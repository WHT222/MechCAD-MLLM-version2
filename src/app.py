#!/usr/bin/env python3
"""
MechCAD-MLLM Web UI

åŸºäº Gradio çš„å‰ç«¯ç•Œé¢ï¼Œæ”¯æŒï¼š
1. è®­ç»ƒç›‘æ§ï¼šå®æ—¶æŸ¥çœ‹è®­ç»ƒæ›²çº¿
2. æ¨¡å‹é¢„æµ‹ï¼šåŠ è½½æ¨¡å‹ç”Ÿæˆ CAD åºåˆ—
3. ç»“æœå¯è§†åŒ–ï¼šæ˜¾ç¤ºç”Ÿæˆçš„ CAD å‘½ä»¤

ç”¨æ³•:
    python src/app.py --checkpoint outputs/stage1/best.pth
"""

import os
import sys
import json
import glob
import argparse
import subprocess
import numpy as np
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

try:
    import gradio as gr
except ImportError:
    print("è¯·å…ˆå®‰è£… Gradio: pip install gradio")
    sys.exit(1)

import torch
from PIL import Image

from src.model.model import MechCADModel, MechCADConfig
from src.unified_vocab.converter import unified_tokens_to_13d
from src.utils.cad_export import export_from_cad13
from cadlib.macro import *


# ============== å…¨å±€å˜é‡ ==============
MODEL = None
MODEL_PATH = None
OUTPUTS_DIR = os.path.abspath(os.path.join(project_root, "outputs"))
UI_EXPORT_DIR = os.path.join(OUTPUTS_DIR, "ui_generated_models")


# ============== æ¨¡å‹åŠ è½½ ==============
def load_model(checkpoint_path, llava_path="model_weights/llava-hf/llava-1.5-7b-hf"):
    """åŠ è½½æ¨¡å‹"""
    global MODEL, MODEL_PATH

    if MODEL is not None and MODEL_PATH == checkpoint_path:
        return "âœ… æ¨¡å‹å·²åŠ è½½"

    try:
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {checkpoint_path}")
        model_cfg = MechCADConfig()

        model = MechCADModel(
            model_cfg,
            llava_model_name=llava_path,
            num_views=2,
            n_latents=64
        )

        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        model.llm2cad_decoder.load_state_dict(checkpoint['decoder_state_dict'])

        if 'fusion_state_dict' in checkpoint:
            model.multiview_fusion.load_state_dict(checkpoint['fusion_state_dict'])

        device = next(model.llava_model.parameters()).device
        model.llm2cad_decoder.to(device)
        model.multiview_fusion.to(device)
        model.eval()

        MODEL = model
        MODEL_PATH = checkpoint_path

        return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {checkpoint_path}"
    except Exception as e:
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"


# ============== CAD ç”Ÿæˆ ==============
def generate_cad(text_input, image_input, use_image, export_stl, preview_mode):
    """ç”Ÿæˆ CAD åºåˆ—"""
    global MODEL

    if MODEL is None:
        return "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", "", "", None, None, None

    try:
        text_only = not use_image or image_input is None

        # å‡†å¤‡è¾“å…¥
        if text_only:
            batch = {
                'text_caption': [text_input],
                'images': torch.zeros(1, 2, 3, 224, 224)
            }
        else:
            from torchvision.transforms import Compose, Resize, ToTensor, Normalize
            transform = Compose([
                Resize((224, 224)),
                ToTensor(),
                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])

            if isinstance(image_input, np.ndarray):
                image = Image.fromarray(image_input)
            else:
                image = image_input

            image_tensor = transform(image.convert('RGB')).unsqueeze(0).unsqueeze(0)
            image_tensor = image_tensor.expand(-1, 2, -1, -1, -1)

            batch = {
                'text_caption': [text_input],
                'images': image_tensor
            }

        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = MODEL(batch, text_only=text_only)

        # è½¬æ¢ä¸º CAD å‘é‡
        cmd_logits = outputs['command_logits']
        args_logits = outputs['unified_args_logits']

        pred_commands = cmd_logits.argmax(dim=-1).squeeze(0).cpu().numpy()
        pred_args_tokens = args_logits.argmax(dim=-1).squeeze(0).cpu().numpy()

        cad_vec = unified_tokens_to_13d(pred_commands, pred_args_tokens)

        # æˆªæ–­åˆ° EOS
        cad_vec, valid_length = truncate_at_eos(cad_vec)

        # æ ¼å¼åŒ–è¾“å‡º
        formatted_output = format_cad_sequence(cad_vec, valid_length)
        raw_output = format_raw_vector(cad_vec[:valid_length])

        # å¯¼å‡ºæ¨¡å‹æ–‡ä»¶å’Œé¢„è§ˆå›¾
        status = f"âœ… ç”ŸæˆæˆåŠŸ (æœ‰æ•ˆå‘½ä»¤æ•°: {valid_length})"
        preview_path = None
        step_path = None
        stl_path = None

        try:
            out_dir = UI_EXPORT_DIR
            os.makedirs(out_dir, exist_ok=True)
            safe_text = "".join(c if c.isalnum() else "_" for c in text_input).strip("_")
            safe_text = safe_text[:40] if safe_text else "cad"
            stem = f"{safe_text}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"

            artifacts = export_from_cad13(
                cad_vec[:valid_length],
                output_dir=out_dir,
                stem=stem,
                export_step=True,
                export_stl=bool(export_stl),
                export_preview=True,
                preview_mode=preview_mode
            )
            preview_path = os.path.abspath(artifacts['preview_path']) if artifacts.get('preview_path') else None
            step_path = os.path.abspath(artifacts['step_path']) if artifacts.get('step_path') else None
            stl_path = os.path.abspath(artifacts['stl_path']) if artifacts.get('stl_path') else None
        except Exception as export_err:
            status += f"\nâš ï¸ æ¨¡å‹å¯¼å‡ºå¤±è´¥: {export_err}"

        return status, formatted_output, raw_output, preview_path, step_path, stl_path

    except Exception as e:
        import traceback
        return f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n{traceback.format_exc()}", "", "", None, None, None


def truncate_at_eos(cad_vec):
    """åœ¨ EOS å¤„æˆªæ–­"""
    cad_vec = cad_vec.copy()
    eos_positions = np.where(cad_vec[:, 0] == EOS_IDX)[0]

    if len(eos_positions) > 0:
        first_eos = eos_positions[0]
        valid_length = first_eos + 1
    else:
        valid_length = len(cad_vec)

    return cad_vec, valid_length


def format_cad_sequence(cad_vec, valid_length):
    """æ ¼å¼åŒ– CAD åºåˆ—ä¸ºå¯è¯»æ–‡æœ¬"""
    lines = []
    cmd_names = {
        LINE_IDX: "LINE",
        ARC_IDX: "ARC",
        CIRCLE_IDX: "CIRCLE",
        EOS_IDX: "EOS",
        SOL_IDX: "SOL",
        EXT_IDX: "EXTRUDE"
    }

    for i in range(valid_length):
        vec = cad_vec[i]
        cmd_idx = int(vec[0])
        cmd_name = cmd_names.get(cmd_idx, f"UNKNOWN({cmd_idx})")

        if cmd_idx == EOS_IDX:
            lines.append(f"[{i:2d}] {cmd_name}")
            break
        elif cmd_idx == SOL_IDX:
            lines.append(f"[{i:2d}] {cmd_name} (Start of Loop)")
        elif cmd_idx == EXT_IDX:
            angle = int(vec[6])
            pos = int(vec[7])
            params = vec[8:13].tolist()
            lines.append(f"[{i:2d}] {cmd_name}: angle={angle}, pos={pos}, params={params}")
        elif cmd_idx in [LINE_IDX, ARC_IDX, CIRCLE_IDX]:
            params = vec[1:6].tolist()
            lines.append(f"[{i:2d}] {cmd_name}: params={params}")
        else:
            lines.append(f"[{i:2d}] {cmd_name}")

    return "\n".join(lines)


def format_raw_vector(cad_vec):
    """æ ¼å¼åŒ–åŸå§‹å‘é‡"""
    lines = ["[CMD, x, y, alpha, f, r, angle, pos, e1, e2, b, u, s]"]
    lines.append("-" * 60)
    for i, vec in enumerate(cad_vec):
        lines.append(f"[{i:2d}] {vec.tolist()}")
    return "\n".join(lines)


# ============== è®­ç»ƒç›‘æ§ ==============
def load_training_logs(log_dir):
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""
    try:
        from tensorboard.backend.event_processing import event_accumulator

        train_dir = os.path.join(log_dir, 'train.events')
        val_dir = os.path.join(log_dir, 'val.events')

        data = {'train': {}, 'val': {}}

        # åŠ è½½äº‹ä»¶æ–‡ä»¶ - ç›´æ¥ä¼ å…¥ç›®å½•è·¯å¾„ï¼ŒEventAccumulator ä¼šè‡ªåŠ¨åˆå¹¶æ‰€æœ‰äº‹ä»¶æ–‡ä»¶
        for mode, path in [('train', train_dir), ('val', val_dir)]:
            if os.path.isdir(path):
                ea = event_accumulator.EventAccumulator(path)
                ea.Reload()

                for tag in ea.Tags()['scalars']:
                    events = ea.Scalars(tag)
                    # æŒ‰ step æ’åºï¼Œç¡®ä¿æ›²çº¿è¿ç»­
                    sorted_events = sorted(events, key=lambda e: e.step)
                    data[mode][tag] = {
                        'steps': [e.step for e in sorted_events],
                        'values': [e.value for e in sorted_events]
                    }

        return data
    except Exception as e:
        return {'error': str(e)}


def plot_training_curves(log_dir):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    import matplotlib.pyplot as plt

    data = load_training_logs(log_dir)

    if 'error' in data:
        return None, f"âŒ æ— æ³•åŠ è½½æ—¥å¿—: {data['error']}"

    fig, axes = plt.subplots(2, 2, figsize=(12, 8))

    # Loss æ›²çº¿
    ax = axes[0, 0]
    if 'loss' in data['train']:
        ax.plot(data['train']['loss']['steps'], data['train']['loss']['values'], label='Train Loss')
    if 'val_loss' in data['val']:
        ax.plot(data['val']['val_loss']['steps'], data['val']['val_loss']['values'], label='Val Loss')
    ax.set_xlabel('Step')
    ax.set_ylabel('Loss')
    ax.set_title('Loss Curves')
    ax.legend()
    ax.grid(True)

    # Command Loss
    ax = axes[0, 1]
    if 'loss_cmd' in data['train']:
        ax.plot(data['train']['loss_cmd']['steps'], data['train']['loss_cmd']['values'], label='Cmd Loss')
    if 'loss_args' in data['train']:
        ax.plot(data['train']['loss_args']['steps'], data['train']['loss_args']['values'], label='Args Loss')
    ax.set_xlabel('Step')
    ax.set_ylabel('Loss')
    ax.set_title('Component Losses')
    ax.legend()
    ax.grid(True)

    # Learning Rate
    ax = axes[1, 0]
    if 'learning_rate' in data['train']:
        ax.plot(data['train']['learning_rate']['steps'], data['train']['learning_rate']['values'])
    ax.set_xlabel('Step')
    ax.set_ylabel('Learning Rate')
    ax.set_title('Learning Rate Schedule')
    ax.grid(True)

    # Accuracy
    ax = axes[1, 1]
    if 'cmd_accuracy' in data['val']:
        ax.plot(data['val']['cmd_accuracy']['steps'], data['val']['cmd_accuracy']['values'])
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Accuracy')
    ax.set_title('Command Accuracy')
    ax.grid(True)

    plt.tight_layout()

    return fig, "âœ… è®­ç»ƒæ›²çº¿å·²åŠ è½½"


def list_checkpoints(model_dir):
    """åˆ—å‡ºå¯ç”¨çš„æ£€æŸ¥ç‚¹"""
    if not os.path.exists(model_dir):
        return "ç›®å½•ä¸å­˜åœ¨"

    ckpts = []
    for f in os.listdir(model_dir):
        if f.endswith('.pth'):
            path = os.path.join(model_dir, f)
            size = os.path.getsize(path) / (1024 * 1024)  # MB
            mtime = os.path.getmtime(path)
            ckpts.append(f"{f} ({size:.1f} MB)")

    return "\n".join(ckpts) if ckpts else "æ— æ£€æŸ¥ç‚¹"


def load_test_metrics_file(metrics_path):
    """
    è¯»å–è®­ç»ƒåä¿å­˜çš„æµ‹è¯•æŒ‡æ ‡ JSONã€‚
    æ”¯æŒä¼ å…¥æ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä¼ å…¥æ¨¡å‹ç›®å½•ï¼ˆè‡ªåŠ¨è¯»å– test_metrics.jsonï¼‰ã€‚
    """
    try:
        if not metrics_path:
            return {}, "âŒ è¯·è¾“å…¥æŒ‡æ ‡æ–‡ä»¶è·¯å¾„æˆ–æ¨¡å‹ç›®å½•"

        if os.path.isdir(metrics_path):
            metrics_path = os.path.join(metrics_path, "test_metrics.json")

        if not os.path.exists(metrics_path):
            return {}, f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {metrics_path}"

        with open(metrics_path, "r", encoding="utf-8") as f:
            payload = json.load(f)

        status = f"âœ… å·²åŠ è½½æµ‹è¯•æŒ‡æ ‡: {metrics_path}"
        return payload, status
    except Exception as e:
        return {}, f"âŒ è¯»å–å¤±è´¥: {e}"


def _get_metric(payload, paths, default=None):
    """ä»å¤šä¸ªå€™é€‰è·¯å¾„é‡Œè¯»å–ç¬¬ä¸€ä¸ªå­˜åœ¨çš„æŒ‡æ ‡å€¼ã€‚"""
    for path in paths:
        cur = payload
        ok = True
        for key in path:
            if not isinstance(cur, dict) or key not in cur:
                ok = False
                break
            cur = cur[key]
        if ok:
            return cur
    return default


def summarize_metrics(payload):
    """ç”Ÿæˆè¯„ä¼°æ‘˜è¦ã€è¡¨æ ¼å’Œå¯è§†åŒ–å›¾ã€‚"""
    import matplotlib.pyplot as plt

    if not isinstance(payload, dict) or len(payload) == 0:
        return "âŒ æŒ‡æ ‡å†…å®¹ä¸ºç©º", [], None, None

    checkpoint = payload.get("checkpoint", "æœªçŸ¥")
    split_name = payload.get("split", "test")
    timestamp = payload.get("timestamp", "æœªçŸ¥")
    validate_loss = _get_metric(payload, [["validate_loss"], ["test_loss"]], default=None)

    cmd_acc = _get_metric(payload, [
        ["validate_metrics", "cmd_accuracy"],
        ["test_metrics", "cmd_accuracy"],
        ["eval_metrics", "cmd_accuracy"]
    ], default=-1.0)
    args_mae = _get_metric(payload, [["eval_metrics", "args_mae"]], default=-1.0)
    chamfer = _get_metric(payload, [["eval_metrics", "chamfer_distance"]], default=-1.0)
    sege = _get_metric(payload, [["eval_metrics", "sege"]], default=-1.0)
    dangel = _get_metric(payload, [["eval_metrics", "dangel"]], default=-1.0)
    dangel_norm = _get_metric(payload, [["eval_metrics", "dangel_norm"]], default=-1.0)

    c_valid = _get_metric(payload, [["eval_metrics", "chamfer_valid_count"]], default=-1)
    c_failed = _get_metric(payload, [["eval_metrics", "chamfer_failed_count"]], default=-1)
    m_valid = _get_metric(payload, [["eval_metrics", "mesh_valid_count"]], default=-1)
    m_failed = _get_metric(payload, [["eval_metrics", "mesh_failed_count"]], default=-1)

    summary_lines = [
        f"æ£€æŸ¥ç‚¹: {checkpoint}",
        f"è¯„ä¼°åˆ’åˆ†: {split_name}",
        f"æ—¶é—´æˆ³: {timestamp}",
    ]
    if validate_loss is not None:
        summary_lines.append(f"éªŒè¯æŸå¤±: {float(validate_loss):.6f}")
    if cmd_acc is not None and float(cmd_acc) >= 0:
        summary_lines.append(f"å‘½ä»¤å‡†ç¡®ç‡: {float(cmd_acc) * 100:.2f}%")
    if args_mae is not None and float(args_mae) >= 0:
        summary_lines.append(f"å‚æ•° MAE: {float(args_mae):.6f}")
    if chamfer is not None and float(chamfer) >= 0:
        summary_lines.append(f"Chamfer Distance: {float(chamfer):.6f}")
    if sege is not None and float(sege) >= 0:
        summary_lines.append(f"SegE: {float(sege):.6f}")
    if dangel is not None and float(dangel) >= 0:
        summary_lines.append(f"DangEL: {float(dangel):.6f}")
    if dangel_norm is not None and float(dangel_norm) >= 0:
        summary_lines.append(f"DangEL(norm): {float(dangel_norm):.6f}")

    summary_text = "\n".join(summary_lines)

    rows = []
    if cmd_acc is not None and float(cmd_acc) >= 0:
        rows.append(["cmd_accuracy", float(cmd_acc)])
    if args_mae is not None and float(args_mae) >= 0:
        rows.append(["args_mae", float(args_mae)])
    if chamfer is not None and float(chamfer) >= 0:
        rows.append(["chamfer_distance", float(chamfer)])
    if sege is not None and float(sege) >= 0:
        rows.append(["sege", float(sege)])
    if dangel is not None and float(dangel) >= 0:
        rows.append(["dangel", float(dangel)])
    if dangel_norm is not None and float(dangel_norm) >= 0:
        rows.append(["dangel_norm", float(dangel_norm)])
    if c_valid >= 0:
        rows.append(["chamfer_valid_count", int(c_valid)])
    if c_failed >= 0:
        rows.append(["chamfer_failed_count", int(c_failed)])
    if m_valid >= 0:
        rows.append(["mesh_valid_count", int(m_valid)])
    if m_failed >= 0:
        rows.append(["mesh_failed_count", int(m_failed)])

    metric_labels = []
    metric_values = []
    if cmd_acc is not None and float(cmd_acc) >= 0:
        metric_labels.append("cmd_acc(%)")
        metric_values.append(float(cmd_acc) * 100.0)
    if args_mae is not None and float(args_mae) >= 0:
        metric_labels.append("args_mae")
        metric_values.append(float(args_mae))
    if chamfer is not None and float(chamfer) >= 0:
        metric_labels.append("chamfer")
        metric_values.append(float(chamfer))
    if sege is not None and float(sege) >= 0:
        metric_labels.append("sege")
        metric_values.append(float(sege))
    if dangel is not None and float(dangel) >= 0:
        metric_labels.append("dangel")
        metric_values.append(float(dangel))
    if dangel_norm is not None and float(dangel_norm) >= 0:
        metric_labels.append("dangel_norm")
        metric_values.append(float(dangel_norm))

    metric_fig = None
    if len(metric_labels) > 0:
        metric_fig, ax = plt.subplots(figsize=(8, 4))
        bars = ax.bar(metric_labels, metric_values, color="#4c78a8")
        ax.set_title("è¯„ä¼°æŒ‡æ ‡æ€»è§ˆ")
        ax.set_ylabel("Value")
        ax.grid(True, axis="y", alpha=0.3)
        ax.bar_label(bars, fmt="%.4f", padding=2, fontsize=8)
        plt.xticks(rotation=20, ha="right")
        plt.tight_layout()

    count_fig = None
    count_labels = []
    count_values = []
    if c_valid >= 0:
        count_labels.append("chamfer_valid")
        count_values.append(int(c_valid))
    if c_failed >= 0:
        count_labels.append("chamfer_failed")
        count_values.append(int(c_failed))
    if m_valid >= 0:
        count_labels.append("mesh_valid")
        count_values.append(int(m_valid))
    if m_failed >= 0:
        count_labels.append("mesh_failed")
        count_values.append(int(m_failed))

    if len(count_labels) > 0:
        count_fig, ax2 = plt.subplots(figsize=(8, 3.5))
        bars2 = ax2.bar(count_labels, count_values, color="#72b7b2")
        ax2.set_title("å‡ ä½•è¯„ä¼°æ ·æœ¬ç»Ÿè®¡")
        ax2.set_ylabel("Count")
        ax2.grid(True, axis="y", alpha=0.3)
        ax2.bar_label(bars2, padding=2, fontsize=8)
        plt.xticks(rotation=15, ha="right")
        plt.tight_layout()

    return summary_text, rows, metric_fig, count_fig


def load_metrics_and_visualize(metrics_path):
    """è¯»å–æŒ‡æ ‡å¹¶è¿”å›å¯è§†åŒ–ç»“æœã€‚"""
    payload, status = load_test_metrics_file(metrics_path)
    if not payload:
        return {}, status, "âŒ æ— æ³•ç”Ÿæˆå¯è§†åŒ–", [], None, None

    summary_text, rows, metric_fig, count_fig = summarize_metrics(payload)
    return payload, status, summary_text, rows, metric_fig, count_fig


def run_evaluation_and_visualize(
    checkpoint_path,
    text_only,
    split_name,
    batch_size,
    num_selected_views,
    n_latents,
    category_start,
    category_end,
    sample_limit,
    full_eval_max_samples,
    deterministic_views,
    skip_full_eval,
    metrics_output_path,
):
    """ä»å‰ç«¯è§¦å‘è¯„ä¼°è„šæœ¬ï¼Œç„¶ååŠ è½½å¹¶å¯è§†åŒ–è¯„ä¼°ç»“æœã€‚"""
    try:
        if not checkpoint_path:
            return "", {}, "âŒ è¯·è¾“å…¥ checkpoint è·¯å¾„", "âŒ æ— æ³•ç”Ÿæˆå¯è§†åŒ–", [], None, None, ""

        ckpt_abs = os.path.abspath(checkpoint_path)
        if not os.path.exists(ckpt_abs):
            return "", {}, f"âŒ checkpoint ä¸å­˜åœ¨: {ckpt_abs}", "âŒ æ— æ³•ç”Ÿæˆå¯è§†åŒ–", [], None, None, ""

        if metrics_output_path and metrics_output_path.strip():
            metrics_abs = os.path.abspath(metrics_output_path.strip())
        else:
            metrics_abs = os.path.join(os.path.dirname(ckpt_abs), f"{split_name}_metrics.json" if split_name != "test" else "test_metrics.json")

        log_dir = os.path.join(
            OUTPUTS_DIR,
            "eval_logs",
            f"ui_eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        os.makedirs(os.path.dirname(metrics_abs), exist_ok=True)

        eval_script = os.path.join(project_root, "src", "evaluate_checkpoint.py")
        cmd = [
            sys.executable,
            eval_script,
            "--checkpoint", ckpt_abs,
            "--split", str(split_name),
            "--batch_size", str(int(batch_size)),
            "--num_selected_views", str(int(num_selected_views)),
            "--n_latents", str(int(n_latents)),
            "--category_start", str(int(category_start) if category_start is not None else 0),
            "--full_eval_max_samples", str(int(full_eval_max_samples)),
            "--metrics_output", metrics_abs,
            "--log_dir", log_dir,
        ]
        if category_end is not None and str(category_end).strip() != "":
            cmd.extend(["--category_end", str(int(float(category_end)))])
        if sample_limit is not None and str(sample_limit).strip() != "":
            cmd.extend(["--sample_limit", str(int(float(sample_limit)))])
        if text_only:
            cmd.append("--text_only")
        if deterministic_views:
            cmd.append("--deterministic_views")
        if skip_full_eval:
            cmd.append("--skip_full_eval")

        proc = subprocess.run(
            cmd,
            cwd=project_root,
            capture_output=True,
            text=True,
            check=False,
        )
        run_log = (proc.stdout or "") + ("\n" + proc.stderr if proc.stderr else "")

        if proc.returncode != 0:
            status = f"âŒ è¯„ä¼°æ‰§è¡Œå¤±è´¥ (exit={proc.returncode})"
            return metrics_abs, {}, status, "âŒ æ— æ³•ç”Ÿæˆå¯è§†åŒ–", [], None, None, run_log

        payload, status = load_test_metrics_file(metrics_abs)
        if not payload:
            return metrics_abs, {}, f"âš ï¸ è¯„ä¼°å®Œæˆä½†è¯»å–æŒ‡æ ‡å¤±è´¥: {status}", "âŒ æ— æ³•ç”Ÿæˆå¯è§†åŒ–", [], None, None, run_log

        summary_text, rows, metric_fig, count_fig = summarize_metrics(payload)
        status = f"âœ… è¯„ä¼°å®Œæˆå¹¶å·²åŠ è½½: {metrics_abs}"
        return metrics_abs, payload, status, summary_text, rows, metric_fig, count_fig, run_log
    except Exception as e:
        return "", {}, f"âŒ è¯„ä¼°å¼‚å¸¸: {e}", "âŒ æ— æ³•ç”Ÿæˆå¯è§†åŒ–", [], None, None, ""


# ============== Gradio ç•Œé¢ ==============
def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""

    with gr.Blocks(title="MechCAD-MLLM", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ğŸ”§ MechCAD-MLLM æ§åˆ¶å°")
        gr.Markdown("å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ CAD ç”Ÿæˆç³»ç»Ÿ")

        with gr.Tabs():
            # ===== æ¨¡å‹é¢„æµ‹ =====
            with gr.TabItem("ğŸ¯ æ¨¡å‹é¢„æµ‹"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### æ¨¡å‹åŠ è½½")
                        ckpt_path = gr.Textbox(
                            label="æ£€æŸ¥ç‚¹è·¯å¾„",
                            placeholder="outputs/checkpoints/best.pth",
                            value="outputs/stage1/best.pth"
                        )
                        load_btn = gr.Button("åŠ è½½æ¨¡å‹", variant="primary")
                        load_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

                        gr.Markdown("### è¾“å…¥")
                        text_input = gr.Textbox(
                            label="æ–‡æœ¬æè¿°",
                            placeholder="A cylinder with a central hole",
                            lines=3
                        )
                        use_image = gr.Checkbox(label="ä½¿ç”¨å›¾åƒï¼ˆå¤šæ¨¡æ€æ¨¡å¼ï¼‰", value=False)
                        image_input = gr.Image(label="è¾“å…¥å›¾åƒ", visible=False)
                        export_stl = gr.Checkbox(label="å¯¼å‡º STL æ–‡ä»¶", value=False)
                        preview_mode = gr.Radio(
                            choices=[("ç‚¹äº‘é¢„è§ˆï¼ˆé»˜è®¤ï¼Œç¨³å®šï¼‰", "pointcloud"), ("STEPæ¸²æŸ“é¢„è§ˆï¼ˆOCCï¼‰", "occ_step")],
                            value="pointcloud",
                            label="é¢„è§ˆè½¬æ¢æ–¹å¼"
                        )

                        generate_btn = gr.Button("ç”Ÿæˆ CAD åºåˆ—", variant="primary")

                    with gr.Column(scale=1):
                        gr.Markdown("### è¾“å‡º")
                        gen_status = gr.Textbox(label="ç”ŸæˆçŠ¶æ€", interactive=False)
                        cad_output = gr.Textbox(
                            label="CAD å‘½ä»¤åºåˆ—",
                            lines=15,
                            interactive=False
                        )
                        raw_output = gr.Textbox(
                            label="åŸå§‹å‘é‡",
                            lines=10,
                            interactive=False
                        )
                        preview_image = gr.Image(
                            label="æ¨¡å‹é¢„è§ˆå›¾",
                            type="filepath",
                            interactive=False
                        )
                        step_file = gr.File(label="STEP æ–‡ä»¶", interactive=False)
                        stl_file = gr.File(label="STL æ–‡ä»¶", interactive=False)

                # äº‹ä»¶ç»‘å®š
                load_btn.click(load_model, inputs=[ckpt_path], outputs=[load_status])
                use_image.change(lambda x: gr.update(visible=x), inputs=[use_image], outputs=[image_input])
                generate_btn.click(
                    generate_cad,
                    inputs=[text_input, image_input, use_image, export_stl, preview_mode],
                    outputs=[gen_status, cad_output, raw_output, preview_image, step_file, stl_file]
                )

            # ===== è®­ç»ƒç›‘æ§ =====
            with gr.TabItem("ğŸ“Š è®­ç»ƒç›‘æ§"):
                with gr.Row():
                    with gr.Column(scale=1):
                        log_dir = gr.Textbox(
                            label="æ—¥å¿—ç›®å½•",
                            placeholder="outputs/logs",
                            value="outputs/stage1_log"
                        )
                        refresh_btn = gr.Button("åˆ·æ–°è®­ç»ƒæ›²çº¿", variant="primary")
                        log_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

                    with gr.Column(scale=1):
                        model_dir = gr.Textbox(
                            label="æ¨¡å‹ç›®å½•",
                            placeholder="outputs/checkpoints",
                            value="outputs/checkpoints"
                        )
                        list_btn = gr.Button("åˆ—å‡ºæ£€æŸ¥ç‚¹")
                        ckpt_list = gr.Textbox(label="å¯ç”¨æ£€æŸ¥ç‚¹", lines=5, interactive=False)

                with gr.Row():
                    train_plot = gr.Plot(label="è®­ç»ƒæ›²çº¿")

                with gr.Row():
                    with gr.Column(scale=1):
                        metrics_path = gr.Textbox(
                            label="æµ‹è¯•æŒ‡æ ‡æ–‡ä»¶/ç›®å½•",
                            placeholder="outputs/checkpoints/test_metrics.json æˆ– outputs/checkpoints",
                            value="outputs/checkpoints/test_metrics.json"
                        )
                        load_metrics_btn = gr.Button("è¯»å–æµ‹è¯•æŒ‡æ ‡", variant="primary")
                        metrics_status = gr.Textbox(label="æŒ‡æ ‡è¯»å–çŠ¶æ€", interactive=False)
                    with gr.Column(scale=1):
                        metrics_json = gr.JSON(label="æµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡")

                refresh_btn.click(plot_training_curves, inputs=[log_dir], outputs=[train_plot, log_status])
                list_btn.click(list_checkpoints, inputs=[model_dir], outputs=[ckpt_list])
                load_metrics_btn.click(load_test_metrics_file, inputs=[metrics_path], outputs=[metrics_json, metrics_status])

            # ===== æŒ‡æ ‡è¯„ä¼° =====
            with gr.TabItem("ğŸ“ˆ æŒ‡æ ‡è¯„ä¼°"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### æ–¹å¼1ï¼šè¯»å–å·²æœ‰æŒ‡æ ‡æ–‡ä»¶")
                        eval_metrics_path = gr.Textbox(
                            label="æŒ‡æ ‡æ–‡ä»¶/ç›®å½•",
                            placeholder="outputs/stage2/test_metrics.json æˆ– outputs/stage2",
                            value="outputs/checkpoints/test_metrics.json"
                        )
                        eval_load_btn = gr.Button("åŠ è½½å¹¶å¯è§†åŒ–", variant="primary")
                        eval_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
                        eval_summary = gr.Textbox(label="è¯„ä¼°æ‘˜è¦", lines=9, interactive=False)
                    with gr.Column(scale=1):
                        eval_json = gr.JSON(label="åŸå§‹æŒ‡æ ‡ JSON")
                        eval_table = gr.Dataframe(
                            label="å…³é”®æŒ‡æ ‡è¡¨",
                            headers=["Metric", "Value"],
                            datatype=["str", "number"],
                            interactive=False
                        )

                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### æ–¹å¼2ï¼šä¸€é”®è¿è¡Œè¯„ä¼°å¹¶å¯è§†åŒ–")
                        run_ckpt_path = gr.Textbox(
                            label="Checkpoint è·¯å¾„",
                            placeholder="outputs/stage2/best.pth",
                            value="outputs/stage2/best.pth"
                        )
                        with gr.Row():
                            run_text_only = gr.Checkbox(label="text_onlyï¼ˆé˜¶æ®µ1ï¼‰", value=False)
                            run_deterministic_views = gr.Checkbox(label="å›ºå®šè§†å›¾é‡‡æ ·", value=True)
                            run_skip_full_eval = gr.Checkbox(label="ä»…validateï¼ˆè·³è¿‡å‡ ä½•æŒ‡æ ‡ï¼‰", value=False)
                        with gr.Row():
                            run_split = gr.Dropdown(
                                choices=["test", "val", "train", "all"],
                                value="test",
                                label="è¯„ä¼°æ•°æ®åˆ’åˆ†"
                            )
                            run_batch_size = gr.Number(label="batch_size", value=4, precision=0)
                            run_eval_max_samples = gr.Number(label="full_eval_max_samples", value=500, precision=0)
                        with gr.Row():
                            run_num_views = gr.Number(label="num_selected_views", value=2, precision=0)
                            run_n_latents = gr.Number(label="n_latents", value=64, precision=0)
                        with gr.Row():
                            run_category_start = gr.Number(label="category_start", value=0, precision=0)
                            run_category_end = gr.Textbox(
                                label="category_endï¼ˆå¯é€‰ï¼‰",
                                placeholder="ä¾‹å¦‚ 9ï¼Œç•™ç©ºè¡¨ç¤ºå…¨éƒ¨",
                                value=""
                            )
                            run_sample_limit = gr.Textbox(
                                label="sample_limitï¼ˆå¯é€‰ï¼‰",
                                placeholder="ä¾‹å¦‚ 200ï¼Œç•™ç©ºè¡¨ç¤ºå…¨éƒ¨",
                                value=""
                            )
                        run_metrics_output = gr.Textbox(
                            label="è¾“å‡ºæŒ‡æ ‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                            placeholder="ç•™ç©ºåˆ™é»˜è®¤å†™åˆ° checkpoint åŒç›®å½•",
                            value=""
                        )
                        run_eval_btn = gr.Button("è¿è¡Œè¯„ä¼°å¹¶åŠ è½½ç»“æœ", variant="primary")
                    with gr.Column(scale=1):
                        run_log = gr.Textbox(
                            label="è¯„ä¼°æ‰§è¡Œæ—¥å¿—",
                            lines=14,
                            interactive=False
                        )

                with gr.Row():
                    eval_metric_plot = gr.Plot(label="æŒ‡æ ‡å¯è§†åŒ–")
                    eval_count_plot = gr.Plot(label="æœ‰æ•ˆ/å¤±è´¥æ ·æœ¬ç»Ÿè®¡")

                eval_load_btn.click(
                    load_metrics_and_visualize,
                    inputs=[eval_metrics_path],
                    outputs=[eval_json, eval_status, eval_summary, eval_table, eval_metric_plot, eval_count_plot]
                )
                run_eval_btn.click(
                    run_evaluation_and_visualize,
                    inputs=[
                        run_ckpt_path,
                        run_text_only,
                        run_split,
                        run_batch_size,
                        run_num_views,
                        run_n_latents,
                        run_category_start,
                        run_category_end,
                        run_sample_limit,
                        run_eval_max_samples,
                        run_deterministic_views,
                        run_skip_full_eval,
                        run_metrics_output,
                    ],
                    outputs=[
                        eval_metrics_path,
                        eval_json,
                        eval_status,
                        eval_summary,
                        eval_table,
                        eval_metric_plot,
                        eval_count_plot,
                        run_log,
                    ]
                )

            # ===== ç¤ºä¾‹ =====
            with gr.TabItem("ğŸ“ ç¤ºä¾‹"):
                gr.Markdown("""
                ### ç¤ºä¾‹æ–‡æœ¬æè¿°

                å°è¯•ä»¥ä¸‹æè¿°æ¥ç”Ÿæˆ CAD æ¨¡å‹ï¼š

                
                - `Generate a CAD model with a square base and a central circular hole`
                - `Generate a CAD model with a rectangular prism shape, featuring a uniform gray color and smooth surfaces`
                - `Generate a CAD model with a cylindrical shape featuring a hollow center and a split along one side, resembling a segmented ring`


                ### ä½¿ç”¨æç¤º

                1. **çº¯æ–‡æœ¬æ¨¡å¼**: é€‚åˆç¬¬ä¸€é˜¶æ®µè®­ç»ƒçš„æ¨¡å‹
                2. **å¤šæ¨¡æ€æ¨¡å¼**: éœ€è¦ç¬¬äºŒé˜¶æ®µè®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä¸Šä¼ å‚è€ƒå›¾åƒ
                3. **æ£€æŸ¥ç‚¹é€‰æ‹©**: `best.pth` é€šå¸¸æ˜¯éªŒè¯æŸå¤±æœ€ä½çš„æ¨¡å‹
                """)

            # ===== å…³äº =====
            with gr.TabItem("â„¹ï¸ å…³äº"):
                gr.Markdown("""
                ### MechCAD-MLLM

                **å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ CAD ç”Ÿæˆç³»ç»Ÿ**

                #### åŠŸèƒ½ç‰¹ç‚¹
                - ğŸ”¤ æ–‡æœ¬åˆ° CADï¼šæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆ CAD å‘½ä»¤åºåˆ—
                - ğŸ–¼ï¸ å¤šæ¨¡æ€èåˆï¼šç»“åˆå›¾åƒå’Œæ–‡æœ¬è¿›è¡Œ CAD ç”Ÿæˆ
                - ğŸ”„ æ¸è¿›å¼è®­ç»ƒï¼šæ”¯æŒä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
                - ğŸ“Š è®­ç»ƒç›‘æ§ï¼šå®æ—¶æŸ¥çœ‹è®­ç»ƒæ›²çº¿

                #### æŠ€æœ¯æ¶æ„
                - ç¼–ç å™¨ï¼šLLaVA-1.5-7Bï¼ˆå†»ç»“ï¼‰
                - å¤šè§†å›¾èåˆï¼šPerceiverFusion
                - è§£ç å™¨ï¼šTransformer Decoder
                - è¯è¡¨ï¼šç»Ÿä¸€å¤§è¯è¡¨ï¼ˆ47651 tokensï¼‰

                #### å‘½ä»¤æ ¼å¼
                - `LINE`: ç›´çº¿å‘½ä»¤
                - `ARC`: åœ†å¼§å‘½ä»¤
                - `CIRCLE`: åœ†å‘½ä»¤
                - `EXTRUDE`: æ‹‰ä¼¸å‘½ä»¤
                - `SOL`: å¾ªç¯å¼€å§‹
                - `EOS`: åºåˆ—ç»“æŸ
                """)

    return app


# ============== ä¸»å‡½æ•° ==============
def main():
    parser = argparse.ArgumentParser(description="MechCAD-MLLM Web UI")
    parser.add_argument("--checkpoint", type=str, default=None,
                        help="é¢„åŠ è½½çš„æ£€æŸ¥ç‚¹è·¯å¾„")
    parser.add_argument("--port", type=int, default=7860,
                        help="æœåŠ¡ç«¯å£")
    parser.add_argument("--share", action="store_true",
                        help="åˆ›å»ºå…¬å…±é“¾æ¥")

    args = parser.parse_args()

    # é¢„åŠ è½½æ¨¡å‹
    if args.checkpoint:
        print(load_model(args.checkpoint))

    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    app = create_ui()
    app.launch(
        server_name="0.0.0.0",
        server_port=args.port,
        share=args.share,
        allowed_paths=[OUTPUTS_DIR]
    )


if __name__ == "__main__":
    main()
